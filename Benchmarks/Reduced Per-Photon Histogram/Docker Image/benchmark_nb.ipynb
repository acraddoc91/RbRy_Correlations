{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is an example notebook to demonstrate how the docker container can be used with Jupyter\n",
    "\n",
    "# Some important things to note: the only directories exposed to the outside world should be /home/rbry,\n",
    "# which is mounted at runtime and the /NAS folder, which contains the lab NAS. If you save anything NOT in these folders\n",
    "# it'll be lost when the container closes\n",
    "#\n",
    "# The /NAS folder should have the same directory structure as it does if you mounted the NAS in windows, i.e. if the NAS\n",
    "# on Windows is the Z: drive and you're trying to get to something in the Z:/Data folder it'll be in /NAS/Data here.\n",
    "# Python doesn't deal well with '\\' to seperate directories (which is what Windows does) so make sure you're using '/'\n",
    "# if you copy a filename/folder name over\n",
    "#\n",
    "# The raw code for all this stuff can be found here: https://github.com/acraddoc91/PythonCorrelationsAllCPU/tree/master/pythonDLLCPU_linux/docker_image\n",
    "#\n",
    "# Due to the way Jupyter works you won't be able to see the block progress in this window, but it will be displayed in the\n",
    "# command window that you started the Docker container from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library which does all the correlations wizardry\n",
    "import corrLib\n",
    "#Required to capture stdout from underlying C/C++ functions\n",
    "from wurlitzer import pipes\n",
    "%load_ext wurlitzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 1.089907169342041s\n",
      "Finished in 1.190941572189331s\n"
     ]
    }
   ],
   "source": [
    "# Example on how to use the processFiles function. This is the function you'll probably want to use most of the time if\n",
    "# you're calculating CW g2 or g3 correlations\n",
    "\n",
    "# Flags which dictate whether g2 and/or g3 processing is performed\n",
    "calc_g2 = True\n",
    "calc_g3 = True\n",
    "\n",
    "# Flag dictates whether the normalisation factor should be calculated\n",
    "calc_norm = True\n",
    "\n",
    "# Flag dictates whether the .mat file will be updated or written from scratch\n",
    "update_mat = False\n",
    "\n",
    "#Flag dictates whether we should calculate the photon counts/rates\n",
    "calc_singles_rates = True\n",
    "\n",
    "# Folder where the data is, remember to include a trailing '/'\n",
    "folder_name = \"/NAS/Data/Correlation Data/test_sandy/\"\n",
    "\n",
    "# Name of outputted .mat file\n",
    "mat_file = \"/NAS/Data/Processed Correlations/For Sandy/test_new\"\n",
    "\n",
    "# These again should be self explanatory\n",
    "max_tau = 6e-6\n",
    "bin_width = 20e-9\n",
    "\n",
    "# This is the normalisation stuff, the coincidences are sampled at the norm_distance. To get good statistics for the\n",
    "# normalisation we do this at a few discrete points: -max_norm_jump*norm_distance, (1-max_norm_jump)*norm_distance...\n",
    "# max_norm_jump*norm_distance. Note: coicidences are not calculated where there might be interesting stuff going on, e.g.\n",
    "# if (n-max_norm_jump) = 0 coincidences will not be calculated\n",
    "norm_distance = 100e-6\n",
    "max_norm_jump = 4\n",
    "\n",
    "#This is the channel pairs that g2 will be calculated for. It should be a list of 2 elements lists\n",
    "#which contain channel pairs with the channels referred to by their physical channel number\n",
    "pairwise_channel_list = [[3,5],[3,8],[5,8]]\n",
    "\n",
    "#This is the channel triplets that g3 will be calculated for. It should be a list of 3 elements lists\n",
    "#which contain channel triplets with the channels referred to by their physical channel number\n",
    "tripwise_channel_list = [[3,5,8]]\n",
    "\n",
    "#This is the list of the offsets for the various channels\n",
    "offset_list = [[3,181],[5,157],[8,0]]\n",
    "\n",
    "corrLib.processFiles(calc_g2,calc_g3,folder_name,mat_file,max_tau,bin_width,norm_distance,max_norm_jump,calc_norm,update_mat,calc_singles_rates,pairwise_channel_list,tripwise_channel_list,offset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find 3, 5 & 8 channel trip\n",
      "Chunking 0 files into 1 blocks\n",
      "Bin Width\tPulse Spacing\tMax Pulse Distance\n",
      "20.081200ns\t1.004060us\t1\n",
      "Min time 2\tMax time 2\tMin time 3\tMax time 3\n",
      "-12.008558us\t12.008558us\t0.000000us\t6.004279us\n",
      "Finished block 1 of 1\n",
      "Finished g3 in 0.32956957817077637s\n",
      "Tot time\tMasked block time\n",
      "0.000000\t0.000000\n",
      "Count info:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example on how to use the processFiles_with_taus function. This is the function you'll probably want to use most of the time if\n",
    "# you're calculating CW g2 or g3 correlations\n",
    "\n",
    "# Flags which dictate whether g2 and/or g3 processing is performed\n",
    "calc_g2 = False\n",
    "calc_g3 = True\n",
    "\n",
    "# Flag dictates whether the normalisation factor should be calculated\n",
    "calc_norm = True\n",
    "\n",
    "# Flag dictates whether the .mat file will be updated or written from scratch\n",
    "update_mat = True\n",
    "\n",
    "#Flag dictates whether we should calculate the photon counts/rates\n",
    "calc_singles_rates = True\n",
    "\n",
    "# Folder where the data is, remember to include a trailing '/'\n",
    "folder_name = \"/NAS/Data/Correlation Data/g2_sandy/\"\n",
    "\n",
    "# Name of outputted .mat file\n",
    "mat_file = \"/NAS/Data/Processed Correlations/For Sandy/test_new\"\n",
    "\n",
    "# These again should be self explanatory\n",
    "max_tau_g2 = 6e-6\n",
    "max_tau_2_g3 = 12e-6\n",
    "min_tau_2_g3 = -12e-6\n",
    "max_tau_3_g3 = 6e-6\n",
    "min_tau_3_g3 = 0e-6\n",
    "bin_width = 20e-9\n",
    "\n",
    "# This is the normalisation stuff, the coincidences are sampled at the norm_distance. To get good statistics for the\n",
    "# normalisation we do this at a few discrete points: -max_norm_jump*norm_distance, (1-max_norm_jump)*norm_distance...\n",
    "# max_norm_jump*norm_distance. Note: coicidences are not calculated where there might be interesting stuff going on, e.g.\n",
    "# if (n-max_norm_jump) = 0 coincidences will not be calculated\n",
    "norm_distance = 1e-6\n",
    "max_norm_jump = 1\n",
    "\n",
    "#This is the channel pairs that g2 will be calculated for. It should be a list of 2 elements lists\n",
    "#which contain channel pairs with the channels referred to by their physical channel number\n",
    "pairwise_channel_list = [[3,5],[3,8],[5,8]]\n",
    "\n",
    "#This is the channel triplets that g3 will be calculated for. It should be a list of 3 elements lists\n",
    "#which contain channel triplets with the channels referred to by their physical channel number\n",
    "tripwise_channel_list = [[3,5,8]]\n",
    "\n",
    "#This is the list of the offsets for the various channels\n",
    "offset_list = [[3,33],[5,0],[8,0]]\n",
    "\n",
    "corrLib.processFiles_with_taus(calc_g2,calc_g3,folder_name,mat_file,max_tau_g2,min_tau_2_g3,max_tau_2_g3,min_tau_3_g3,max_tau_3_g3,bin_width,norm_distance,max_norm_jump,calc_norm,update_mat,calc_singles_rates,pairwise_channel_list,tripwise_channel_list,offset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example on how to use the g2ToFile_pulse function. This is the function that calculates 2d coincidences in tau_1 and tau_2\n",
    "# space, where tau_1 and tau_2 are times from some clock line\n",
    "\n",
    "# Folder where the data is, remember to include a trailing '/'\n",
    "folder_name = \"/NAS/Data/Correlation Data/2018/November/29/5us_wait/\"\n",
    "\n",
    "# Name of outputted .mat file\n",
    "mat_file = \"/NAS/Data/Processed Correlations/2018/November/29/5us_wait_1us_bin\"\n",
    "\n",
    "# These should probably be self explanatory\n",
    "min_tau_1 = 0\n",
    "max_tau_1 = 250e-6\n",
    "min_tau_2 = -2*255e-6\n",
    "max_tau_2 = 3*255e-6\n",
    "bin_width = 1e-6\n",
    "\n",
    "# Run the command\n",
    "corrLib.g2ToFile_pulse(folder_name,mat_file,min_tau_1,max_tau_1,min_tau_2,max_tau_2,bin_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 7.664816856384277s\n"
     ]
    }
   ],
   "source": [
    "#Example on how to use the countTags function. This function calculates the number of masked and unmasked tags for\n",
    "#each channel in the channel list. Along with the total masked and unmasked time\n",
    "\n",
    "#Folder name to look at\n",
    "folder_name = \"/NAS/Data/Correlation Data/test_sandy/\"\n",
    "#List of channels to look at, these should be defined in the same way as they are on the tagger itself\n",
    "channel_list = [3,5,8]\n",
    "\n",
    "corrLib.countTags(folder_name,channel_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
